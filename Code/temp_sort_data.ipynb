{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def census_diff(df, census):\n",
    "\n",
    "    grp = df.groupby([\"plot\",  census])\n",
    "    cen = grp.date.agg(['min', 'max'])\n",
    "    cen[\"mid\"] = (cen[\"min\"] + (cen[\"max\"] - cen[\"min\"])/2).dt.date\n",
    "    cen[\"difference\"] = cen[\"mid\"].diff().astype('timedelta64[D]')\n",
    "    cen.loc[cen[\"difference\"] < 0 , \"difference\"] = np.NAN\n",
    "    cen[\"diff_yrs\"] = cen.difference/365\n",
    "\n",
    "    cen.reset_index(level=0, inplace=True)\n",
    "    cen.reset_index(level=0, inplace=True)\n",
    "\n",
    "    cen[census].astype(str)\n",
    "    cen[\"step\"] = cen[census].astype(str).shift() + \"-\" + cen[census].astype(str)\n",
    "    cen.loc[cen[\"difference\"].isnull(), \"step\"] = np.NaN\n",
    "    cen.index = cen['plot'] + \"_\" + cen['step']\n",
    "\n",
    "    return cen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open general data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open plot locations\n",
    "with open('../Data/rows.geojson') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "properties = pd.DataFrame()\n",
    "\n",
    "# add each line of geojson file to dataframe\n",
    "for i in range(0, len(data['features'])):\n",
    "    properties = properties.append(pd.DataFrame(data['features'][i]['properties'], index = [i]))\n",
    "\n",
    "# only really care about these columns\n",
    "properties = properties.loc[: , [\"plot_size\",\n",
    "                                 \"centroid_y\",\n",
    "                                 \"centroid_x\",\n",
    "                                 \"fractal_order\",\n",
    "                                 \"location\"]]\n",
    "\n",
    "properties.rename(columns={'centroid_y':'longitude', 'centroid_x':'latitude'}, inplace=True)\n",
    "properties[\"longlat\"] = properties.apply(lambda x: [x.longitude, x.latitude], axis=1)\n",
    "\n",
    "# seperate dataframe for only second order fractal points\n",
    "second_order = properties.loc[properties.fractal_order == 2, : ]\n",
    "\n",
    "# function to find point closest to given point\n",
    "def closest(pt, others):\n",
    "    \n",
    "    clst_pt = min(others.longlat, key = lambda x: geodesic(pt, x).meters)\n",
    "        \n",
    "    return others.location.loc[others.longlat.apply(lambda x: x == clst_pt)].reset_index(drop = True)\n",
    "\n",
    "\n",
    "# fractal nesting and agb data\n",
    "fpn = pd.read_csv(\"../Data/Fractal_point_nesting.csv\")\n",
    "agb = pd.read_csv(\"../Data/AGB.csv\")\n",
    "\n",
    "# specific wanted columns - and rename ***(going with Chave moist)***\n",
    "agb = agb[[\"field_name\", \"Plot\", \"Date\", \"AGB_Chave_moist\", \"ForestQuality\"]]\n",
    "agb.columns = [\"field_name\", \"plot\", \"date\", \"agb\", \"forestquality\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mammals Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open and sort the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open each seperate plot\n",
    "E  = pd.read_csv(\"../Data/small_mammals/test/E_test.csv\")\n",
    "F  = pd.read_csv(\"../Data/small_mammals/test/F_test.csv\")\n",
    "D  = pd.read_csv(\"../Data/small_mammals/test/D_test.csv\")\n",
    "OG = pd.read_csv(\"../Data/small_mammals/test/OG_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to sort out each plot in turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_mams(df):\n",
    "\n",
    "    # new column names\n",
    "    ncolnames   = [\"occasion\", \"date\", \"grid\", \"point\", \"trap\", \"trap_id\", \"species\"]\n",
    "    df.columns  = ncolnames\n",
    "\n",
    "    # stupid formatting sorted\n",
    "    df[\"occasion\"]  = df.occasion.str.replace(\"--\", \"-\")\n",
    "    df[\"grid\"]      = df.grid.str.replace(\"--\", \"-\")\n",
    "    df[\"trap_id\"]   = df.trap_id.str.replace(\"--\", \"-\")\n",
    "    df[\"trap_id\"]   = df.trap_id.apply(lambda x: x[:-1])\n",
    "    df[\"date\"]      = pd.to_datetime(df.date)\n",
    "    df[\"year\"]      = df.date.dt.year\n",
    "    df[\"census\"]    = df.occasion.str.partition(\"-\")[2].str.partition(\"-\")[2]\n",
    "    df[\"plot\"]      = df.occasion.str[0]\n",
    "    \n",
    "    return df\n",
    "\n",
    "E  = sort_mams(E)\n",
    "F  = sort_mams(F)\n",
    "D  = sort_mams(D)\n",
    "OG = sort_mams(OG)\n",
    "\n",
    "frames = [E, F, D, OG]\n",
    "\n",
    "mamls_df = pd.concat(frames, sort = False)\n",
    "\n",
    "mamls_df[\"species\"] = mamls_df.species.fillna(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### match with species names from lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mammals species lookup table \n",
    "m_lkup = pd.read_csv(\"../Data/small_mammals/mammals_lookup.csv\")\n",
    "m_lkup.columns = [\"code\", \"species\", \"scientific\"]\n",
    "\n",
    "mamls_df[\"species\"] = mamls_df.species.str.strip()\n",
    "\n",
    "\n",
    "# my fairly questionable decisions...\n",
    "\n",
    "# if its a questionmark - I just go with it\n",
    "# if its an either or I go with the first one!\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"CTRS-but see notes\", \"species\"] = \"CTRS\"\n",
    "\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"SS?\",          \"species\"] = \"SS\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"WH?\",          \"species\"] = \"WH\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"PR?\",          \"species\"] = \"PR\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"RR?\",          \"species\"] = \"RR\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"MR?\",          \"species\"] = \"MR\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"MR??\",         \"species\"] = \"MR\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"RS?\",          \"species\"] = \"RS\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"LGTRS?\",       \"species\"] = \"LGTRS\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"BS?\",          \"species\"] = \"BS\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"PSQ\",          \"species\"] = \"LSQ\"      # not confident on this\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"BSQ\",          \"species\"] = \"BSQ?\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"SSQ\",          \"species\"] = \"SSQ?\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"RS or SS\" ,    \"species\"] = \"RS\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"WH or SS\",     \"species\"] = \"WH\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"BS/RS?\",       \"species\"] = \"BS\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"PTSQ?\",        \"species\"] = \"PTSQ\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"LETRS\",        \"species\"] = \"LETRS?\"   # for some reason the lookup table has a ?\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"CBS?\",         \"species\"] = \"CBS\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"SL?TRS\",       \"species\"] = \"SLTRS\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"SLTRS?\",       \"species\"] = \"SLTRS\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"L?TRS\",        \"species\"] = \"SLTRS\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"LSQ?\",         \"species\"] = \"LSQ\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"CTRS?\",        \"species\"] = \"CTRS\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"LTRS or CTRS\", \"species\"] = \"CTRS\"     # went with CTRS as LTRS could refer to a couple\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"LTRS\",         \"species\"] = \"LETRS?\"   # not convinced about this one\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"Squirrel\",     \"species\"] = \"squirrel\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"DTT_DEAD\",     \"species\"] = \"DTT\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"LSQ?_DEAD\",    \"species\"] = \"LSQ\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"squirrel\",     \"species\"] = \"unknown\"  # ***mmm?***\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"See notes\",    \"species\"] = \"unknown\"  # i'm effectivley treating 'unknown' as a seperate species which seems spurious at best \n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"??\",           \"species\"] = \"unknown\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"?\",            \"species\"] = \"unknown\"\n",
    "mamls_df.loc[mamls_df.loc[:, \"species\"] == \"Unknown\",      \"species\"] = \"unknown\"\n",
    "\n",
    "# merge\n",
    "mamls_df = pd.merge(mamls_df,\n",
    "                    m_lkup[[\"code\", \"scientific\"]],\n",
    "                    how      = \"left\",\n",
    "                    left_on  = \"species\",\n",
    "                    right_on = \"code\")\n",
    "\n",
    "# get rid of the leftovers... (there were a couple of birds/reptiles)\n",
    "mamls_df = mamls_df.loc[-mamls_df.code.isna(), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find closest f2 point to each trap and get agb measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the unique trap names\n",
    "trap_locs = pd.DataFrame({\"trap_id\" : mamls_df.trap_id.unique()})\n",
    "\n",
    "trap_locs = trap_locs.merge(properties[[\"location\", \"longlat\"]],\n",
    "                            how      = \"left\",\n",
    "                            left_on  = \"trap_id\",\n",
    "                            right_on = \"location\")\n",
    "\n",
    "# find the closest second order fractal point\n",
    "trap_locs[\"second_order\"] = trap_locs.longlat.apply(lambda x: closest(x, second_order))\n",
    "\n",
    "# merge back to master dataframe\n",
    "mamls_df = mamls_df.merge(trap_locs, how = \"left\", on = \"trap_id\")\n",
    "\n",
    "# just want the point number \n",
    "mamls_df.second_order = mamls_df.second_order.str[-3:]\n",
    "mamls_df.second_order = mamls_df.second_order.astype(int)\n",
    "\n",
    "# merge to get agb and forest quality\n",
    "mamls_df = mamls_df.merge(agb[[\"plot\", \"agb\", \"forestquality\"]], how = \"left\",\n",
    "                          left_on = \"second_order\", right_on = \"plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### final cleanup and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mamls_df = mamls_df.rename(index=str, columns={\"plot_x\": \"plot\"})\n",
    "\n",
    "mamls_df = mamls_df[[\"occasion\",\n",
    "                     \"date\",\n",
    "                     \"grid\",\n",
    "                     \"point\",\n",
    "                     \"trap\",\n",
    "                     \"trap_id\",\n",
    "                     \"species\",\n",
    "                     \"year\",\n",
    "                     \"plot\",\n",
    "                     \"census\",\n",
    "                     \"scientific\",\n",
    "                     \"longlat\",\n",
    "                     \"second_order\",\n",
    "                     \"agb\",\n",
    "                     \"forestquality\"]]\n",
    "\n",
    "mamls_df.to_csv(\"../Results/mammals_sorted2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the species/plot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i'll give four different combinations a go...\n",
    "mamls_df[\"trap_year\"]   = mamls_df[\"plot\"] + \"_\" + mamls_df.trap_id + \"_\" + mamls_df.year.astype(str)\n",
    "mamls_df[\"grid_year\"]   = mamls_df[\"plot\"] + \"_\" + mamls_df.grid    + \"_\" + mamls_df.year.astype(str)\n",
    "mamls_df[\"trap_census\"] = mamls_df[\"plot\"] + \"_\" + mamls_df.trap_id + \"_\" + mamls_df.census\n",
    "mamls_df[\"grid_census\"] = mamls_df[\"plot\"] + \"_\" + mamls_df.grid    + \"_\" + mamls_df.census\n",
    "\n",
    "# function to make matrix\n",
    "def make_matrix(df, what):\n",
    "    mx = df.groupby([what, \"species\"]).size().unstack()  # groupby whatever i've chosen and species\n",
    "    mx = mx.fillna(value = 0)                            # fill with 0's\n",
    "    mx = mx.drop(\"None\", axis = 1)                       # so we keep plot row even if nothing was trapped\n",
    "    return mx\n",
    "\n",
    "# do\n",
    "mamls_TY = make_matrix(mamls_df, \"trap_year\")\n",
    "mamls_GY = make_matrix(mamls_df, \"grid_year\")\n",
    "mamls_TC = make_matrix(mamls_df, \"trap_census\")\n",
    "mamls_GC = make_matrix(mamls_df, \"grid_census\")\n",
    "\n",
    "# save\n",
    "mamls_TY.to_csv(\"../Results/m_trap-year.csv\")\n",
    "mamls_GY.to_csv(\"../Results/m_grid-year.csv\")\n",
    "mamls_TC.to_csv(\"../Results/m_trap-census.csv\")\n",
    "mamls_GC.to_csv(\"../Results/m_grid_census.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### agb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the agb (either mean or median of all the traps in plot)\n",
    "mamls_agb = mamls_df.groupby(\"plot\").agb.describe()\n",
    "mamls_agb = pd.DataFrame(mamls_agb[\"50%\"])\n",
    "mamls_agb.to_csv(\"../Results/mamls_agb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardise time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and time difference between cesuses - i'm doing year or occasion...\n",
    "mamls_cn_diff = census_diff(mamls_df, \"census\")\n",
    "mamls_yr_diff = census_diff(mamls_df, \"year\")\n",
    "\n",
    "mamls_yr_diff = mamls_yr_diff.rename(index=str, columns={\"year\": \"census\"})\n",
    "\n",
    "mamls_cn_diff.to_csv(\"../Results/mammals_census_dates.csv\")\n",
    "mamls_yr_diff.to_csv(\"../Results/mammals_years_dates.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### readin raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readin RAW data\n",
    "tree_df = pd.read_csv(\"../Data/SAFE_CarbonPlots_Tree+LianaCensus.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to sort everything out for each census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_data(df, census_no):  # give new column names, delete NAs and dead...\n",
    "\n",
    "    # consistant and better column names\n",
    "    new_Cnames = ['f_type',       # forest type\n",
    "                  'plot',\n",
    "                  'subplot',\n",
    "                  'date',         # date of measurements\n",
    "                  'observers',\n",
    "                  'tag_no',\n",
    "                  'd_pom',        # diameter of tree (cm)\n",
    "                  'h_pom',        # height diameter is taken (m) 1.3 by default\n",
    "                  'height',\n",
    "                  'flag',         # condition of trees (see flag list)\n",
    "                  'alive',        # 1 = yes, NaN = no\n",
    "                  'stem_C',       # aboveground biomass of tree (kg)\n",
    "                  'root_C',       # root biomass of tree\n",
    "                  'field_cmnts',  # comments from field\n",
    "                  'data_cmnts',   # comments from data entry\n",
    "                  'sbplt_X',\n",
    "                  'sbplt_Y',\n",
    "                  'CPA',          # projected area of the crown of the stem\n",
    "                  'X_FMC',        # plot level X coordinate\n",
    "                  'Y_FMC',        # plot level Y coordinte\n",
    "                  'Z_FMC',        # plot level elevation\n",
    "                  'family',\n",
    "                  'binomial',\n",
    "                  'wood_density']\n",
    "\n",
    "    # give each census these column names\n",
    "    df.columns = new_Cnames\n",
    "\n",
    "    # get unique ID - combine plot and tag_no\n",
    "    df = df.assign(ID = df['plot'] + df['tag_no'].map(str))\n",
    "\n",
    "    # column with census number\n",
    "    df = df.assign(census = census_no)\n",
    "\n",
    "    # delete rows with NaNs in important columns\n",
    "    impt_cols = ['tag_no', 'd_pom', 'h_pom', 'height', 'flag', 'alive',\n",
    "                 'stem_C', 'root_C']\n",
    "\n",
    "    df = df.dropna(subset = impt_cols, how = 'all')\n",
    "\n",
    "    # delete dead trees (alive == 0)\n",
    "    df = df[df.alive == 1]\n",
    "\n",
    "    # sort out dates\n",
    "    df.date = pd.to_datetime(df.date, dayfirst = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subset each census - weird column things..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset for each census\n",
    "census_1 = tree_df.iloc[ :, list(range(0, 3))     # same for all\n",
    "                          + list(range(3, 15))    # specific for census\n",
    "                          + list(range(53, 62))]  # same for all\n",
    "\n",
    "census_2 = tree_df.iloc[ :, list(range(0, 3))\n",
    "                          + list(range(15, 27))\n",
    "                          + list(range(53, 62))]\n",
    "\n",
    "census_3 = tree_df.iloc[ :, list(range(0, 3))\n",
    "                          + list(range(27, 39))\n",
    "                          + list(range(53, 62))]\n",
    "\n",
    "census_4 = tree_df.iloc[ :, list(range(0, 3))\n",
    "                          + list(range(39, 51))\n",
    "                          + list(range(53, 62))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do function and combine census'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort data for each census\n",
    "census_1 = sort_data(census_1, 1)\n",
    "census_2 = sort_data(census_2, 2)\n",
    "census_3 = sort_data(census_3, 3)\n",
    "census_4 = sort_data(census_4, 4)\n",
    "\n",
    "# recombine all census data (stack on top of each other)\n",
    "tree_df = pd.concat([census_1, census_2, census_3, census_4], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add extra columns and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add genus column\n",
    "tree_df['plot']        = tree_df['plot'].replace(\" \", \"\", regex=True)\n",
    "tree_df['subplot']     = tree_df['subplot'].apply(lambda x: str(x).zfill(2))\n",
    "tree_df['genus']       = tree_df.apply(lambda row: row.binomial.split(\" \")[0], axis = 1)\n",
    "tree_df['plt_sub']     = tree_df['plot'] + \"_sp\" + tree_df['subplot'].astype(str)\n",
    "tree_df['plt_sub_cen'] = tree_df['plt_sub'] + \"_c\" + tree_df['census'].astype(str)\n",
    "tree_df['plot_c']      = tree_df['plot'] + \"_c\" + tree_df['census'].astype(str)\n",
    "tree_df['census']      = \"c\" + tree_df.census.astype(str)\n",
    "\n",
    "# save to csv\n",
    "tree_df.to_csv(\"../Results/trees_sorted.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# species matrix\n",
    "tree_matrix = tree_df.groupby(['plt_sub_cen', 'binomial']).size().unstack()\n",
    "tree_matrix = tree_matrix.fillna(value = 0)\n",
    "tree_matrix.to_csv(\"../Results/trees_matrix.csv\")\n",
    "\n",
    "tree_genus_matrix = tree_df.groupby(['plt_sub_cen', 'genus']).size().unstack()\n",
    "tree_genus_matrix = tree_genus_matrix.fillna(value = 0)\n",
    "tree_genus_matrix.to_csv(\"../Results/trees_genus_matrix.csv\")\n",
    "\n",
    "tree_family_matrix = tree_df.groupby(['plt_sub_cen', 'family']).size().unstack()\n",
    "tree_family_matrix = tree_family_matrix.fillna(value = 0)\n",
    "tree_family_matrix.to_csv(\"../Results/trees_family_matrix.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trees agb (different from the others as calculated from data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total biomass at each census for each plot\n",
    "trees_agb = pd.DataFrame(tree_df.groupby([\"plot\", \"census\"]).stem_C.sum())\n",
    "\n",
    "# take the mean of all census' 0.0625 and 0.001 to get it into Mg/0.0625 ha\n",
    "trees_agb = pd.DataFrame(trees_agb.groupby(\"plot\").mean()*  0.0625 * 0.001)\n",
    "\n",
    "trees_agb.to_csv(\"../Results/trees_agb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trees census standardise time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_cen = census_diff(tree_df, \"census\")\n",
    "tree_cen.to_csv(\"../Results/trees_census_dates.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
